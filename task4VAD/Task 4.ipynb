{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff067115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc10c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import time\n",
    "from IPython.display import Audio \n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ed0838d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x12d561b20>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://medium.com/analytics-vidhya/pytorch-for-deep-learning-lstm-for-sequence-data-d0708fdf5717\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_folder = \"/Users/will/Documents/COM4511/ass/COM4511/task4VAD/audio\"\n",
    "labs_folder = \"/Users/will/Documents/COM4511/ass/COM4511/task4VAD/labels\"\n",
    "\n",
    "training_prefixes = [\"N\", \"V\"]\n",
    "validation_prefixes = [\"E\"]\n",
    "testing_prefixes = [\"C\"]\n",
    "\n",
    "# reading training data\n",
    "\n",
    "def read_data_to_list(prefixes):\n",
    "    data_out = []\n",
    "    labs_out = []\n",
    "    os.chdir(data_folder)\n",
    "    for file in os.listdir():\n",
    "        if file[0] in prefixes:\n",
    "            path = f\"{data_folder}/{file}\"\n",
    "            with open(path, 'rb') as f:\n",
    "                data_out.append(np.load(f))\n",
    "    \n",
    "    os.chdir(labs_folder)\n",
    "    for file in os.listdir():\n",
    "        if file[0] in prefixes:\n",
    "            path = f\"{labs_folder}/{file}\"\n",
    "            with open(path, 'rb') as f:\n",
    "                labs_out.append(np.load(f))\n",
    "                \n",
    "    return data_out, labs_out\n",
    "    \n",
    "    \n",
    "training_data, training_labs =  read_data_to_list(training_prefixes)\n",
    "\n",
    "testing_data, testing_labs =  read_data_to_list(testing_prefixes)\n",
    "validation_data, validation_labs =  read_data_to_list(validation_prefixes)\n",
    "\n",
    "\n",
    "class Timeseries(Dataset):\n",
    "    def __init__(self, x, y, seq_len):\n",
    "        self.x = torch.from_numpy(x)\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = x.shape[0]\n",
    "        self.seq_len = seq_len\n",
    "    \n",
    "    # def __getitem__(self, idx):\n",
    "    #     return self.transform(self.x[idx]), self.transform(self.y[idx])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx:idx+self.seq_len], torch.tensor(self.y[idx:idx+self.seq_len], dtype=torch.float32)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len - (self.seq_len - 1)\n",
    "\n",
    "sequence_length = 2048\n",
    "\n",
    "train_datasets = [Timeseries(x, y, seq_len=sequence_length) for (x, y) in zip(training_data, training_labs)]\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(torch.utils.data.ConcatDataset(train_datasets), shuffle=True, batch_size=512) \n",
    "\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "da8ab3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4474c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm = nn.LSTM(13, 1) # input MFCCs are 13 dim, output is 1 dim as it is binary classification\n",
    "# hidden = (torch.randn(1, 1, 13),\n",
    "#           torch.randn(1, 1, 1))\n",
    "\n",
    "\n",
    "\n",
    "class LSTM_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM_network,self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=13,hidden_size=5,num_layers=1,batch_first=True)\n",
    "        self.fc1 = nn.Linear(in_features=5,out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        output,_status = self.lstm(x)\n",
    "        output = self.fc1(torch.relu(output))\n",
    "        return self.sigmoid(output)\n",
    "\n",
    "model = LSTM_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fc41e398",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.BCELoss() # binary classfication task, BCEL is obvious choice.\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.0005) # https://deepdatascience.wordpress.com/2016/11/18/which-lstm-optimizer-to-use/\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5d4f8ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/var/folders/mv/bqcl5_px1hj1wvz7mrnzkk540000gn/T/ipykernel_2735/4209296287.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return self.x[idx:idx+self.seq_len], torch.tensor(self.y[idx:idx+self.seq_len], dtype=torch.float32)\n",
      "1it [00:02,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th data sample, loss: 1.0024621486663818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [02:25,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100th data sample, loss: 0.8601197004318237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [04:42,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200th data sample, loss: 0.6748944520950317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [07:07,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300th data sample, loss: 0.5558712482452393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "382it [09:17,  1.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mv/bqcl5_px1hj1wvz7mrnzkk540000gn/T/ipykernel_2735/1179655800.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training løøp\n",
    "for e in range(epochs):\n",
    "    data_shape = 1048576\n",
    "    for i, data in tqdm(enumerate(train_loader)):\n",
    "        \n",
    "        \n",
    "        y_pred = model(data[0][:]).reshape(-1, 1)\n",
    "        # .reshape(data_shape)\n",
    "        loss = crit(y_pred, data[:][1].reshape(-1, 1))\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f\"{i}th data sample, loss: {loss}\")\n",
    "    print(f\"{e}th epoch, loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade48b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761db843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e4fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a1cf7199e2c41d63b48ed1d5e80bd73b8082f141724ef71c5588fe270d6c9c9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('3.8.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
