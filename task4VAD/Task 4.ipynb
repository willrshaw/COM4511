{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff067115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc10c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import time\n",
    "from IPython.display import Audio \n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ed0838d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1216a06a0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://medium.com/analytics-vidhya/pytorch-for-deep-learning-lstm-for-sequence-data-d0708fdf5717\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_folder = \"/Users/will/Documents/COM4511/ass/COM4511/task4VAD/audio\"\n",
    "labs_folder = \"/Users/will/Documents/COM4511/ass/COM4511/task4VAD/labels\"\n",
    "\n",
    "training_prefixes = [\"N\", \"V\"]\n",
    "validation_prefixes = [\"E\"]\n",
    "testing_prefixes = [\"C\"]\n",
    "\n",
    "# reading training data\n",
    "\n",
    "def read_data_to_list(prefixes):\n",
    "    data_out = []\n",
    "    labs_out = []\n",
    "    os.chdir(data_folder)\n",
    "    for file in os.listdir():\n",
    "        if file[0] in prefixes:\n",
    "            path = f\"{data_folder}/{file}\"\n",
    "            with open(path, 'rb') as f:\n",
    "                data_out.append(np.load(f))\n",
    "    \n",
    "    os.chdir(labs_folder)\n",
    "    for file in os.listdir():\n",
    "        if file[0] in prefixes:\n",
    "            path = f\"{labs_folder}/{file}\"\n",
    "            with open(path, 'rb') as f:\n",
    "                labs_out.append(np.load(f))\n",
    "                \n",
    "    return data_out, labs_out\n",
    "    \n",
    "    \n",
    "training_data, training_labs =  read_data_to_list(training_prefixes)\n",
    "\n",
    "testing_data, testing_labs =  read_data_to_list(testing_prefixes)\n",
    "validation_data, validation_labs =  read_data_to_list(validation_prefixes)\n",
    "\n",
    "\n",
    "class Timeseries(Dataset):\n",
    "    def __init__(self, x, y, seq_len):\n",
    "        self.x = torch.from_numpy(x)\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = x.shape[0]\n",
    "        self.seq_len = seq_len\n",
    "    \n",
    "    # def __getitem__(self, idx):\n",
    "    #     return self.transform(self.x[idx]), self.transform(self.y[idx])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx:idx+self.seq_len], torch.tensor(self.y[idx:idx+self.seq_len], dtype=torch.float32)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len - (self.seq_len - 1)\n",
    "\n",
    "sequence_length = 1024\n",
    "\n",
    "train_datasets = [Timeseries(x, y, seq_len=sequence_length) for (x, y) in zip(training_data, training_labs)]\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(torch.utils.data.ConcatDataset(train_datasets), shuffle=True, batch_size=32) \n",
    "\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "da8ab3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4474c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm = nn.LSTM(13, 1) # input MFCCs are 13 dim, output is 1 dim as it is binary classification\n",
    "# hidden = (torch.randn(1, 1, 13),\n",
    "#           torch.randn(1, 1, 1))\n",
    "\n",
    "\n",
    "\n",
    "class LSTM_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM_network,self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=13,hidden_size=8,num_layers=2,batch_first=True)\n",
    "        self.fc1 = nn.Linear(in_features=8,out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        output,_status = self.lstm(x)\n",
    "        output = self.fc1(torch.relu(output))\n",
    "        return self.sigmoid(output)\n",
    "\n",
    "model = LSTM_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fc41e398",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.BCELoss() # binary classfication task, BCEL is obvious choice.\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.0001) # https://deepdatascience.wordpress.com/2016/11/18/which-lstm-optimizer-to-use/\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5d4f8ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/var/folders/mv/bqcl5_px1hj1wvz7mrnzkk540000gn/T/ipykernel_2735/1711219157.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return self.x[idx:idx+self.seq_len], torch.tensor(self.y[idx:idx+self.seq_len], dtype=torch.float32)\n",
      "1it [00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th data sample, loss: 0.7232809662818909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "251it [01:38,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250th data sample, loss: 0.6718465685844421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [03:12,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500th data sample, loss: 0.5381044745445251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "751it [04:49,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750th data sample, loss: 0.4721112847328186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [06:29,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000th data sample, loss: 0.4064949154853821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1251it [08:04,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250th data sample, loss: 0.35460975766181946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1501it [09:39,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500th data sample, loss: 0.37156805396080017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1751it [11:09,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750th data sample, loss: 0.4186086058616638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1882it [12:05,  1.90it/s]"
     ]
    }
   ],
   "source": [
    "# training løøp\n",
    "\n",
    "losses = []\n",
    "for e in range(epochs):\n",
    "    data_shape = 1048576\n",
    "    for i, data in tqdm(enumerate(train_loader)):\n",
    "        \n",
    "        \n",
    "        y_pred = model(data[0][:]).reshape(-1, 1)\n",
    "        # .reshape(data_shape)\n",
    "        loss = crit(y_pred, data[:][1].reshape(-1, 1))\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        if i % 100 == 0:\n",
    "            losses.append(loss)\n",
    "        if i % 250 == 0:\n",
    "            print(f\"{i}th data sample, loss: {loss}\")\n",
    "            \n",
    "    print(f\"{e}th epoch, loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade48b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761db843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e4fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a1cf7199e2c41d63b48ed1d5e80bd73b8082f141724ef71c5588fe270d6c9c9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('3.8.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
